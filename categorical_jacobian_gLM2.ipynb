{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqjacq79TckC"
      },
      "source": [
        "# Get Categorical Jacobian from gLM2\n",
        "Copied from @sokrypton's https://colab.research.google.com/github/sokrypton/ColabBio/blob/main/categorical_jacobian/esm2.ipynb  \n",
        "Minor edits to run gLM2 instead of ESM2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_NAME = \"tattabio/gLM2_650M\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query sequence: ModAC\n",
        "SEQUENCE = \"MFLKVRAEKRLGNFRLNVDFEMGRDYCVLLGPTGAGKSVFLELIAGIVKPDRGEVRLNGADITPLPPERRGIGFVPQDYALFPHLSVYRNIAYGLRNVERVERDRRVREMAEKLGIAHLLDRKPARLSGGERQRVALARALVIQPRLLLLDEPLSAVDLKTKGVLMEELRFVQREFDVPILHVTHDLIEAAMLADEVAVMLNGRIVEKGKLKELFSAKNGEVAEFLSARNLLLKVSKILDMRLLFSALLALLSSIILLFVLLPVAATVTLQLFNFDEFLKAASDPAVWKVVLTTYYAALISTLIAVIFGTPLAYILARKSFPGKSVVEGIVDLPVVIPHTVAGIALLVVFGSSGLIGSFSPLKFVDALPGIVVAMLFVSVPIYINQAKEGFASVDVRLEHVARTLGSSPLRVFFTVSLPLSVRHIVAGAIMSWARGISEFGAVVVIAYYPMIAPTLIYERYLSEGLSAAMPVAAILILLSLAVFVALRIIVGREDVSEGQG\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bokeh.plotting\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.palettes import viridis\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from matplotlib.colors import to_hex\n",
        "import tqdm.notebook\n",
        "\n",
        "bokeh.io.output_notebook()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_gLM2_model(model_name, device=\"cuda\"):\n",
        "    model = AutoModelForMaskedLM.from_pretrained(model_name, trust_remote_code=True).eval().to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    return model, tokenizer\n",
        "\n",
        "def pssm_to_dataframe(pssm, esm_alphabet):\n",
        "  sequence_length = pssm.shape[0]\n",
        "  idx = [str(i) for i in np.arange(1, sequence_length + 1)]\n",
        "  df = pd.DataFrame(pssm, index=idx, columns=list(esm_alphabet))\n",
        "  df = df.stack().reset_index()\n",
        "  df.columns = ['Position', 'Amino Acid', 'Probability']\n",
        "  return df\n",
        "\n",
        "def contact_to_dataframe(con):\n",
        "  sequence_length = con.shape[0]\n",
        "  idx = [str(i) for i in np.arange(1, sequence_length + 1)]\n",
        "  df = pd.DataFrame(con, index=idx, columns=idx)\n",
        "  df = df.stack().reset_index()\n",
        "  df.columns = ['i', 'j', 'value']\n",
        "  return df\n",
        "\n",
        "def pair_to_dataframe(pair,esm_alphabet):\n",
        "  df = pd.DataFrame(pair, index=list(esm_alphabet), columns=list(esm_alphabet))\n",
        "  df = df.stack().reset_index()\n",
        "  df.columns = ['aa_i', 'aa_j', 'value']\n",
        "  return df\n",
        "\n",
        "def parse_fasta(filename, a3m=True):\n",
        "    '''function to parse fasta file'''\n",
        "\n",
        "    if a3m:\n",
        "        # for a3m files the lowercase letters are removed\n",
        "        # as these do not align to the query sequence\n",
        "        rm_lc = str.maketrans(dict.fromkeys(string.ascii_lowercase))\n",
        "\n",
        "    header, sequence = [], []\n",
        "    lines = open(filename, \"r\")\n",
        "    for line in lines:\n",
        "        line = line.rstrip()\n",
        "        if line[0] == \">\":\n",
        "            header.append(line[1:])\n",
        "            sequence.append([])\n",
        "        else:\n",
        "            if a3m:\n",
        "                line = line.translate(rm_lc)\n",
        "            else:\n",
        "                line = line.upper()\n",
        "            sequence[-1].append(line)\n",
        "    lines.close()\n",
        "    sequence = [''.join(seq) for seq in sequence]\n",
        "\n",
        "    return header, sequence\n",
        "\n",
        "\n",
        "def mk_msa(seqs, alphabet=None):\n",
        "    '''one hot encode msa'''\n",
        "    if alphabet is None:\n",
        "        alphabet = \"ARNDCQEGHILKMFPSTWYV-\"\n",
        "    states = len(alphabet)\n",
        "    a2n = {a: n for n, a in enumerate(alphabet)}\n",
        "    msa_ori = np.array([[a2n.get(aa, states-1) for aa in seq] for seq in seqs])\n",
        "    return np.eye(states)[msa_ori]\n",
        "\n",
        "\n",
        "def _do_apc(x, rm_diag=True):\n",
        "    '''given matrix do apc correction'''\n",
        "    if rm_diag:\n",
        "        np.fill_diagonal(x, 0.0)\n",
        "    a1 = x.sum(0, keepdims=True)\n",
        "    a2 = x.sum(1, keepdims=True)\n",
        "    y = x - (a1*a2)/x.sum()\n",
        "    np.fill_diagonal(y, 0.0)\n",
        "    return y\n",
        "\n",
        "\n",
        "def inv_cov(Y):\n",
        "    '''given one-hot encoded MSA, return contacts'''\n",
        "    N, L, A = Y.shape\n",
        "    Y_flat = Y.reshape(N, -1)\n",
        "    c = np.cov(Y_flat.T)\n",
        "    shrink = 4.5/np.sqrt(N) * np.eye(c.shape[0])\n",
        "    ic = np.linalg.inv(c + shrink)\n",
        "    raw = np.sqrt(np.square(ic.reshape(L, A, L, A)\n",
        "                  [:, :20, :, :20]).sum((1, 3)))\n",
        "    return {\"c\": c, \"ic\": ic,\n",
        "            \"raw\": raw, \"apc\": _do_apc(raw)}\n",
        "\n",
        "def do_apc(x, rm=1):\n",
        "    '''given matrix do apc correction'''\n",
        "    # trying to remove different number of components\n",
        "    # rm=0 remove none\n",
        "    # rm=1 apc\n",
        "    x = np.copy(x)\n",
        "    if rm == 0:\n",
        "        return x\n",
        "    elif rm == 1:\n",
        "        a1 = x.sum(0, keepdims=True)\n",
        "        a2 = x.sum(1, keepdims=True)\n",
        "        y = x - (a1*a2)/x.sum()\n",
        "    else:\n",
        "        # decompose matrix, rm largest(s) eigenvectors\n",
        "        u, s, v = np.linalg.svd(x)\n",
        "        y = s[rm:] * u[:, rm:] @ v[rm:, :]\n",
        "    np.fill_diagonal(y, 0)\n",
        "    return y\n",
        "\n",
        "\n",
        "def get_contacts(x, symm=True, center=True, rm=1):\n",
        "    # convert jacobian (L,A,L,A) to contact map (L,L)\n",
        "    j = x.copy()\n",
        "    if center:\n",
        "        for i in range(4):\n",
        "            j -= j.mean(i, keepdims=True)\n",
        "    j_fn = np.sqrt(np.square(j).sum((1, 3)))\n",
        "    np.fill_diagonal(j_fn, 0)\n",
        "    j_fn_corrected = do_apc(j_fn, rm=rm)\n",
        "    if symm:\n",
        "        j_fn_corrected = (j_fn_corrected + j_fn_corrected.T)/2\n",
        "    return j_fn_corrected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DtRKmskxgHfs"
      },
      "outputs": [],
      "source": [
        "cmap = plt.colormaps[\"bwr_r\"]\n",
        "bwr_r = [to_hex(cmap(i)) for i in np.linspace(0, 1, 256)]\n",
        "cmap = plt.colormaps[\"gray_r\"]\n",
        "gray = [to_hex(cmap(i)) for i in np.linspace(0, 1, 256)]\n",
        "\n",
        "\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model, tokenizer = load_gLM2_model(MODEL_NAME)\n",
        "\n",
        "esm_alphabet = tokenizer.convert_ids_to_tokens(range(4, 25))\n",
        "ALPHABET = \"AFILVMWYDEKRHNQSTGPC\"\n",
        "ALPHABET_map = [esm_alphabet.index(a) for a in ALPHABET]\n",
        "mask_idx = tokenizer.convert_tokens_to_ids('<mask>')\n",
        "\n",
        "def jac_to_con(jac, symm=True, center=True, diag=\"remove\", apc=True):\n",
        "\n",
        "  X = jac.copy()\n",
        "  Lx,Ax,Ly,Ay = X.shape\n",
        "  if Ax == 20:\n",
        "    X = X[:,ALPHABET_map,:,:]\n",
        "\n",
        "  if Ay == 20:\n",
        "    X = X[:,:,:,ALPHABET_map]\n",
        "    if symm and Ax == 20:\n",
        "      X = (X + X.transpose(2,3,0,1))/2\n",
        "\n",
        "  if center:\n",
        "    for i in range(4):\n",
        "      if X.shape[i] > 1:\n",
        "        X -= X.mean(i,keepdims=True)\n",
        "\n",
        "  contacts = np.sqrt(np.square(X).sum((1,3)))\n",
        "\n",
        "  if symm and (Ax != 20 or Ay != 20):\n",
        "    contacts = (contacts + contacts.T)/2\n",
        "\n",
        "  if diag == \"remove\":\n",
        "    np.fill_diagonal(contacts,0)\n",
        "\n",
        "  if diag == \"normalize\":\n",
        "    contacts_diag = np.diag(contacts)\n",
        "    contacts = contacts / np.sqrt(contacts_diag[:,None] * contacts_diag[None,:])\n",
        "\n",
        "  if apc:\n",
        "    ap = contacts.sum(0,keepdims=True) * contacts.sum(1, keepdims=True) / contacts.sum()\n",
        "    contacts = contacts - ap\n",
        "\n",
        "  if diag == \"remove\":\n",
        "    np.fill_diagonal(contacts,0)\n",
        "\n",
        "  return {\"jac\":X, \"contacts\":contacts}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0iY6qZdr7NLq"
      },
      "outputs": [],
      "source": [
        "sequence = SEQUENCE.upper()\n",
        "sequence = ''.join([i for i in sequence if i.isalpha()])\n",
        "\n",
        "PARALLEL = 20\n",
        "if len(sequence) > 1500:\n",
        "  PARALLEL = 10\n",
        "elif len(sequence) > 2400:\n",
        "  PARALLEL = 1\n",
        "\n",
        "os.makedirs(\"output\",exist_ok=True)\n",
        "with open(\"output/README.txt\",\"w\") as handle:\n",
        "  handle.write(\"conservation_logits.txt = (L, A) matrix\\n\")\n",
        "  handle.write(\"coevolution.txt = (L, L) matrix\\n\")\n",
        "  handle.write(\"jac.npy = ((L*L-L)/2, A, A) tensor\\n\")\n",
        "  handle.write(\"jac index can be recreated with np.triu_indices(L,1)\\n\")\n",
        "  handle.write(f\"[A]lphabet: {ALPHABET}\\n\")\n",
        "  handle.write(f\"sequence: {sequence}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_logits(seq, p=1, return_jac=False):\n",
        "  x, ln = tokenizer([seq], return_tensors='pt')['input_ids'].to(DEVICE), len(seq)\n",
        "  if p is None: p = ln\n",
        "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=True):\n",
        "    f = lambda x: model(x).logits[:,:,4:24].detach().cpu().numpy()\n",
        "    logits = np.zeros((ln,20), dtype=np.float32)\n",
        "    if return_jac:\n",
        "      jac = np.zeros((ln,1,ln,20), dtype=np.float32)\n",
        "      fx = f(x.to(DEVICE))[0]\n",
        "    with tqdm.notebook.tqdm(total=ln, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "      for n in range(0,ln,p):\n",
        "        m = min(n+p,ln)\n",
        "        x_h = torch.tile(torch.clone(x),[m-n,1])\n",
        "        for i in range(m-n):\n",
        "          x_h[i,n+i] = mask_idx\n",
        "        fx_h = f(x_h.to(DEVICE))\n",
        "        for i in range(m-n):\n",
        "          logits[n+i] = fx_h[i,n+i]\n",
        "          if return_jac:\n",
        "            jac[n+i] = fx_h[i,None] - fx\n",
        "        pbar.update(m-n)\n",
        "    if return_jac:\n",
        "      return jac\n",
        "    else:\n",
        "      return logits\n",
        "\n",
        "\n",
        "def get_categorical_jacobian(seq, layer=None, fast=False):\n",
        "  # ∂in/∂out\n",
        "  x, ln = tokenizer([seq], return_tensors='pt')['input_ids'].to(DEVICE), len(seq)\n",
        "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=True):\n",
        "    if layer is None:\n",
        "      f = lambda x: model(x).logits[:, :, 4:24].detach().cpu().numpy()\n",
        "    else:\n",
        "      f = lambda x: model(x, output_hidden_states=True).hidden_states[layer].detach().cpu().numpy()\n",
        "\n",
        "    fx = f(x.to(DEVICE))[0]\n",
        "    fx_h = np.zeros([ln, 1 if fast else 20, ln, fx.shape[-1]], dtype=np.float32)\n",
        "    x = x.to(DEVICE) if fast else torch.tile(x, [20, 1]).to(DEVICE)\n",
        "    with tqdm.notebook.tqdm(total=ln, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "      for n in range(ln):  # for each position\n",
        "        x_h = torch.clone(x)\n",
        "\n",
        "        # mutate to all 20 aa\n",
        "        x_h[:, n] = mask_idx if fast else torch.arange(4, 24)\n",
        "        fx_h[n] = f(x_h)\n",
        "        pbar.update(1)\n",
        "\n",
        "  # note: direction here differs from manuscript\n",
        "  # positive = good\n",
        "  # negative = bad\n",
        "  return fx_h - fx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compute Conservation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vcWEjQApY5Fk"
      },
      "outputs": [],
      "source": [
        "model_name = os.path.basename(MODEL_NAME)\n",
        "logits = get_logits(sequence, p=PARALLEL)\n",
        "logits = logits[:,ALPHABET_map]\n",
        "np.savetxt(f\"output/conservation_logits_{model_name}.txt\",logits)\n",
        "pssm = softmax(logits,-1)\n",
        "df = pssm_to_dataframe(pssm, ALPHABET)\n",
        "\n",
        "# plot pssm\n",
        "num_colors = 256  # You can adjust this number\n",
        "palette = viridis(256)\n",
        "TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\"\n",
        "p = figure(title=\"CONSERVATION\",\n",
        "           x_range=[str(x) for x in range(1,len(sequence)+1)],\n",
        "           y_range=list(ALPHABET)[::-1],\n",
        "           width=900, height=400,\n",
        "           tools=TOOLS, toolbar_location='below',\n",
        "           tooltips=[('Position', '@Position'), ('Amino Acid', '@{Amino Acid}'), ('Probability', '@Probability')])\n",
        "\n",
        "r = p.rect(x=\"Position\", y=\"Amino Acid\", width=1, height=1, source=df,\n",
        "           fill_color=linear_cmap('Probability', palette, low=0, high=1),\n",
        "           line_color=None)\n",
        "p.xaxis.visible = False  # Hide the x-axis\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compute Coevolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@markdown Set output `layer` and postprocessing options such as to `center`, [`symm`]etrize, remove [`diag`]onal and to perform average product correction `apc`.\n",
        "#@markdown The `fast` approximation only perturbs the mask token.\n",
        "fast = False # @param {type:\"boolean\"}\n",
        "layer = None # @param [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"None\"] {type:\"raw\"}\n",
        "center = True # @param {type:\"boolean\"}\n",
        "symm = True # @param {type:\"boolean\"}\n",
        "diag = \"remove\" # @param [\"remove\", \"normalize\", \"none\"]\n",
        "apc = True # @param {type:\"boolean\"}\n",
        "settings = dict(layer=layer,\n",
        "                sequence=sequence,\n",
        "                fast=fast)\n",
        "if fast and layer is None:\n",
        "  jac = get_logits(sequence, p=PARALLEL, return_jac=True)\n",
        "else:\n",
        "  jac = get_categorical_jacobian(sequence, layer=layer, fast=fast)\n",
        "settings_ = settings.copy()\n",
        "model_name = os.path.basename(MODEL_NAME)\n",
        "con = jac_to_con(jac, symm=symm, center=center, diag=diag, apc=apc)\n",
        "\n",
        "np.savetxt(f\"output/coevolution_{model_name}.txt\",con[\"contacts\"])\n",
        "if layer is not None:\n",
        "  i,j = np.triu_indices(len(sequence),1)\n",
        "  np.save(f\"output/jac_{model_name}.npy\",con[\"jac\"][i,:,j,:].astype(np.float16))\n",
        "\n",
        "df = contact_to_dataframe(con[\"contacts\"])\n",
        "TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\"\n",
        "p = figure(title=\"COEVOLUTION\",\n",
        "          x_range=[str(x) for x in range(1,len(sequence)+1)],\n",
        "          y_range=[str(x) for x in range(1,len(sequence)+1)][::-1],\n",
        "          width=800, height=800,\n",
        "          tools=TOOLS, toolbar_location='below',\n",
        "          tooltips=[('i', '@i'), ('j', '@j'), ('value', '@value')])\n",
        "\n",
        "r = p.rect(x=\"i\", y=\"j\", width=1, height=1, source=df,\n",
        "          fill_color=linear_cmap('value', gray, low=df.value.min(), high=df.value.max()),\n",
        "          line_color=None)\n",
        "p.xaxis.visible = False  # Hide the x-axis\n",
        "p.yaxis.visible = False  # Hide the x-axis\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t-0NBjgxXI1Y"
      },
      "outputs": [],
      "source": [
        "#@markdown ##select pair of residues to investigate\n",
        "#@markdown Note: 1-indexed (first position is 1)\n",
        "\n",
        "position_i = 402 # @param {type:\"integer\"}\n",
        "position_j = 93 # @param {type:\"integer\"}\n",
        "if layer is None:\n",
        "  if fast:\n",
        "    print(\"this function is only supported when `fast=True`\")\n",
        "  else:\n",
        "    i = position_i - 1\n",
        "    j = position_j - 1\n",
        "    df = pair_to_dataframe(con[\"jac\"][i,:,j,:], ALPHABET)\n",
        "\n",
        "    # plot pssm\n",
        "    TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\"\n",
        "    p = figure(title=f\"coevolution between {position_i} {position_j}\",\n",
        "              x_range=list(ALPHABET),\n",
        "              y_range=list(ALPHABET)[::-1],\n",
        "              width=400, height=400,\n",
        "              tools=TOOLS, toolbar_location='below',\n",
        "              tooltips=[('aa_i', '@aa_i'), ('aa_j', '@aa_j'), ('value', '@value')])\n",
        "    p.xaxis.axis_label = f\"{sequence[i]}{position_i}\"\n",
        "    p.yaxis.axis_label = f\"{sequence[j]}{position_j}\"\n",
        "\n",
        "    r = p.rect(x=\"aa_i\", y=\"aa_j\", width=1, height=1, source=df,\n",
        "               fill_color=linear_cmap('value', bwr_r, low=-3.0, high=3.0),\n",
        "               line_color=None, dilate=True)\n",
        "    show(p)\n",
        "else:\n",
        "  print(\"this function is only supported when `layer=None`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
